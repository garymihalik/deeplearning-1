{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from torch_imports import *\n",
    "from torchtext import vocab, data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.init import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pt_models import *\n",
    "from dataset_pt import *\n",
    "\n",
    "from sgdr_pt import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataLoader():\n",
    "    def __init__(self, src, x_fld, y_fld):\n",
    "        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n",
    "        \n",
    "    def __len__(self): return len(self.src)\n",
    "    \n",
    "    def __iter__(self): \n",
    "        try:\n",
    "            for b in iter(self.src):\n",
    "                yield getattr(b, self.x_fld), getattr(b, self.y_fld).float()\n",
    "        except StopIteration: return\n",
    "\n",
    "def create_td(it): return TextDataLoader(it, 'text', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postproc(arr,vocab,train): \n",
    "    return [1 if o==1 else 0 for o in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up fields\n",
    "TEXT = data.Field(lower=True, fix_length=500)\n",
    "LABEL = data.Field(sequential=False, postprocessing=postproc)\n",
    "\n",
    "# make splits for data\n",
    "trn, test = datasets.IMDB.splits(TEXT, LABEL, root='tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn.fields {'text': <torchtext.data.field.Field object at 0x7fb91016aef0>, 'label': <torchtext.data.field.Field object at 0x7fb91016ae10>}\n",
      "len(trn) 25000\n",
      "vars(trn[0]) {'text': ['i', 'remember', 'when', 'i', 'first', 'saw', 'this', 'short,', 'i', 'was', 'really', 'laughing', 'so', 'hard,', 'that', 'like', 'with', 'a', 'lot', 'of', 'other', 'films', 'that', 'i', 'have', 'seen,', 'no', 'sound', 'came', 'out!', 'curly', 'is', 'really', 'great', 'at', '\"singing\"', 'opera', 'in', 'this', 'one,', 'i', 'am', 'surprised', 'that', 'he', 'did', 'not', 'consider', 'a', 'career', 'as', 'a', 'professional', 'singer,', 'because', 'he', 'was', 'really', 'good!', '<br', '/><br', '/>if', 'you', 'noticed,', 'this', 'was', 'filmed', 'near', 'the', 'end', 'of', \"curly's\", 'career', 'as', 'a', 'stooge,', 'you', 'could', 'really', 'tell', 'he', 'had', 'changed,', 'because', 'he', 'had', 'lost', 'weight', 'and', 'was', 'thinner,', 'his', 'voice', 'was', 'deepening,', 'his', 'face', 'was', 'getting', 'lined', 'with', 'wrinkles,', 'though', 'he', 'still', 'could', 'pull', 'it', 'off,', 'he', 'looked', 'like', 'he', 'was', 'fifty', 'at', 'the', 'age', 'of', 'forty.', 'this', 'was', 'because', 'he', 'was', 'suffering', 'many', 'minor', 'strokes', 'before', 'his', 'big', 'one', 'that', 'ended', 'his', 'career.', 'be', 'he', 'still', 'managed', 'to', 'pull', 'it', 'off', 'in', 'his', 'last', 'ones!', '<br', '/><br', '/>if', 'you', \"don't\", 'mind', 'the', 'fact', 'that', 'curly', 'was', 'really', 'getting', 'very', 'ill', 'at', 'this', 'point,', 'this', 'is', 'actually', 'one', 'of', 'their', 'funniest', 'shorts.', 'i', 'know', 'that', 'i', \"didn't\", 'mind', 'the', 'fact', 'that', 'curly', 'was', 'really', 'changing,', 'because', 'i', 'still', 'thought', 'that', 'he', 'was', 'great!', '<br', '/><br', '/>10/10'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "# print information about the data\n",
    "print('trn.fields', trn.fields)\n",
    "print('len(trn)', len(trn))\n",
    "print('vars(trn[0])', vars(trn[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vectors from .vector_cache/glove.6B.50d.pt\n",
      "len(TEXT.vocab) 5002\n",
      "TEXT.vocab.vectors.size() torch.Size([5002, 50])\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(trn, vectors='glove.6B.50d', max_size=vocab_size)\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "# print vocab information\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'neg', 'pos']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.4180  0.2497 -0.4124  ...  -0.1841 -0.1151 -0.7858\n",
       "          ...             ⋱             ...          \n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "-1.3515  0.5061 -1.9024  ...  -0.3654 -0.6569 -0.7150\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 5002x50]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_iter, test_iter = data.BucketIterator.splits((trn, test), batch_size=64, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_iter, test_iter = data.Iterator.splits((trn, test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[199,\n",
       " 118,\n",
       " 515,\n",
       " 128,\n",
       " 194,\n",
       " 155,\n",
       " 198,\n",
       " 135,\n",
       " 127,\n",
       " 129,\n",
       " 148,\n",
       " 157,\n",
       " 57,\n",
       " 367,\n",
       " 528,\n",
       " 78,\n",
       " 229,\n",
       " 161,\n",
       " 117,\n",
       " 166]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(trn[i].text) for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(trn_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    1     0     1  ...      0   319     1\n",
      "    1   310     1  ...   3052     0     1\n",
      "    1    37     1  ...    729  1071     1\n",
      "       ...          ⋱          ...       \n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "[torch.cuda.LongTensor of size 300x10 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(batch.text[-300:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    1     0     1  ...      0   319     1\n",
      "    1   310     1  ...   3052     0     1\n",
      "    1    37     1  ...    729  1071     1\n",
      "       ...          ⋱          ...       \n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "[torch.cuda.LongTensor of size 300x10 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(batch.text[-300:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.4180  0.2497 -0.4124  0.1217  0.3453 -0.0445 -0.4969 -0.1786 -0.0007 -0.6566\n",
       " 0.2171  0.4651 -0.4676  0.1008  1.0135  0.7484 -0.5310 -0.2626  0.1681  0.1318\n",
       " 0.2682  0.1435 -0.2788  0.0163  0.1138  0.6992 -0.5133 -0.4737 -0.3307 -0.1383\n",
       " 0.7085  0.5709 -0.4716  0.1805  0.5445  0.7260  0.1816 -0.5239  0.1038 -0.1757\n",
       " 0.6805 -0.0393  0.3019 -0.1779  0.4296  0.0322 -0.4138  0.1323 -0.2985 -0.0853\n",
       " 0.6185  0.6425 -0.4655  0.3757  0.7484  0.5374  0.0022 -0.6058  0.2641  0.1170\n",
       " 0.3304  0.2500 -0.6087  0.1092  0.0364  0.1510 -0.5508 -0.0742 -0.0923 -0.3282\n",
       " 0.1189  0.1525 -0.0821 -0.7414  0.7592 -0.4833 -0.3101  0.5148 -0.9871  0.0006\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251637, 5002)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab.freqs), len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad=TEXT.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ModelData('.', create_td(trn_iter), create_td(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=100\n",
    "n_emb=32\n",
    "bs=64\n",
    "nv=len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(m, last_l=-2):\n",
    "    c = children(m)\n",
    "    for l in c:\n",
    "        if isinstance(l, nn.Embedding): \n",
    "            l.weight.data.uniform_(-0.05,0.05)\n",
    "        elif isinstance(l, (nn.Linear, nn.Conv1d)):\n",
    "            xavier_uniform(l.weight.data, gain=calculate_gain('relu'))\n",
    "            l.bias.data.zero_()\n",
    "    xavier_uniform(c[last_l].weight.data, gain=calculate_gain('linear'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Embedding(nv, n_emb, padding_idx=pad, sparse=True),\n",
    "    nn.Dropout(0.01),\n",
    "    Lambda(lambda x: x.transpose(0,1).contiguous().view(x.size(1),-1)),\n",
    "    nn.Linear(500*n_emb, nf),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.7),\n",
    "    nn.Linear(nf, 1),\n",
    "    Lambda(lambda x: x.squeeze())\n",
    ").cuda()\n",
    "\n",
    "init_wgts(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = optim.Adagrad(trainable_params_(m), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86847c4e71f248c0a92de2b4217788bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63274c544c9d487394f292af6072c27f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.416624  0.402875  0.836205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fb8067ba5d4dc4a0e8547e03f2bd51"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.262659  0.334411  0.854348]\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, F.binary_cross_entropy_with_logits, opt, metrics=[accuracy_thresh(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeqSize(nn.Sequential):\n",
    "    def forward(self, x):\n",
    "        for l in self.children():\n",
    "            x = l(x)\n",
    "            print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??F.dropout2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Embedding(nv, n_emb, padding_idx=pad, sparse=True),\n",
    "    Lambda(lambda x: x.permute(1,2,0).contiguous()),\n",
    "    nn.Conv1d(n_emb, n_emb, 5, padding=2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(0.25),\n",
    "    nn.Conv1d(n_emb, n_emb, 5, padding=2, stride=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(0.5),\n",
    "    Flatten(),\n",
    "    nn.Linear(n_emb*500//4, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(100, 1),\n",
    "    Lambda(lambda x: x.squeeze())\n",
    ").cuda()\n",
    "\n",
    "init_wgts(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = optim.Adagrad(trainable_params_(m), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt,1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ba8cf9e835488797cf2039ca45de11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310df46d1c1243998600e97e10a60c46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.675121  0.635704  0.530555]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4e2f367f4f411a9d1fee61c3f70092"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.411029  0.342623  0.823066]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dc17afef2f4037a3ca97f8414f8d62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.337649  0.303579  0.863451]\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 3, F.binary_cross_entropy_with_logits, opt, metrics=[accuracy_thresh(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d8d3130db64f989b2cf0ea19478d39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8ca11266b54a04a563c3409128b1b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.294003  0.299945  0.861493]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce503a88dab14be889a3ea36d1fa2699"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.293427  0.298573  0.862972]\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, F.binary_cross_entropy_with_logits, opt, metrics=[accuracy_thresh(0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def postproc(arr,vocab,train): \n",
    "    return [1 if o==1 else 0 for o in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True)\n",
    "LABEL = data.Field(sequential=False, postprocessing=postproc)\n",
    "trn, test = datasets.IMDB.splits(TEXT, LABEL, root='tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_emb(x): return x.uniform_(-0.05,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vectors from .vector_cache/glove.6B.50d.pt\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(trn, vectors='glove.6B.50d', max_size=vocab_size, unk_init=init_emb)\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pad=TEXT.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_iter, test_iter = data.BucketIterator.splits((trn, test), batch_size=64, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md = ModelData('.', create_td(trn_iter), create_td(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(m):\n",
    "    c = children(m)\n",
    "    for l in c:\n",
    "        if isinstance(l, nn.Embedding): \n",
    "            l.weight.data.uniform_(-0.05,0.05)\n",
    "        elif isinstance(l, (nn.Linear, nn.Conv1d)):\n",
    "            xavier_uniform(l.weight.data, gain=calculate_gain('relu'))\n",
    "            l.bias.data.zero_()\n",
    "    xavier_uniform(c[-2].weight.data, gain=calculate_gain('linear'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class EzLSTM(nn.LSTM):\n",
    "    def __init__(self, input_size, hidden_size, *args, **kwargs):\n",
    "        super().__init__(input_size, hidden_size, *args, **kwargs)\n",
    "        self.num_dirs = 2 if self.bidirectional else 1\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = c0 = Variable(torch.zeros(self.num_dirs,x.size(1),self.hidden_size)).cuda()\n",
    "        outp,_ = super().forward(x, (h0,c0))\n",
    "        return outp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nv=len(TEXT.vocab.itos)\n",
    "hs=70\n",
    "n_emb=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Embedding(nv, n_emb, padding_idx=pad, sparse=True),\n",
    "    nn.Dropout(0.4),\n",
    "    EzLSTM(n_emb, hs, num_layers=1, bidirectional=False),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(hs*1, 1),\n",
    "    Lambda(lambda x: x.squeeze())\n",
    ").cuda()\n",
    "\n",
    "init_wgts(m)\n",
    "\n",
    "m[0].weight.data = TEXT.vocab.vectors.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_opt(p): return optim.Adam(p, betas=(0.,0.999))\n",
    "\n",
    "cl=4\n",
    "lrs=np.array([1e-2, 1e-2])\n",
    "nb=len(md.trn_dl)\n",
    "t=list(split_by_idxs(list(m.children()), [1]))\n",
    "# lo = LayerOptimizer(optim.Adagrad, t, lrs)\n",
    "lo = LayerOptimizer(get_opt, t, lrs)\n",
    "cb=[CosAnneal(lo, nb*cl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt = lo.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbd81a2e29e4e92ac6cc01247e6eb50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b700b7318346088eb0d1cc44086fd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.334644  0.330858  0.865769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a88fd97cb8e48028156428c538facbe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.27686   0.305416  0.872882]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bb305be626467a867d89657a0ee65a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.264897  0.308693  0.873777]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c38cd1d6b44183a6daa9f9bab0ac03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.248931  0.306658  0.874137]\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "### CNN/RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = nn.Sequential(\n",
    "    nn.Embedding(nv, n_emb, padding_idx=pad),\n",
    "    nn.Dropout(0.4),\n",
    "    Lambda(lambda x: x.permute(1,2,0).contiguous()), # b/c/s\n",
    "    nn.Conv1d(n_emb, n_emb*2, 7, padding=3, stride=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout2d(0.4),\n",
    "    Lambda(lambda x: x.permute(2,0,1).contiguous()),   # s/b/c\n",
    "    EzLSTM(n_emb*2, hs, num_layers=1, bidirectional=False),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(hs*1, 1),\n",
    "    Lambda(lambda x: x.squeeze())\n",
    ").cuda()\n",
    "\n",
    "init_wgts(m)\n",
    "m[0].weight.data = TEXT.vocab.vectors.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_opt(p): return optim.Adam(p, betas=(0.,0.999))\n",
    "\n",
    "cl=4\n",
    "lrs=np.array([1e-2, 1e-2])/2\n",
    "nb=len(md.trn_dl)\n",
    "t=list(split_by_idxs(list(m.children()), [1]))\n",
    "lo = LayerOptimizer(get_opt, t, lrs)\n",
    "cb=[CosAnneal(lo, nb*cl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt = lo.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c447c0cf424418a9aaac57634fb952f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5920640a905b462a84d9e263a78ea44f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.543035  0.444902  0.804092]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa1475bf21b452f970b72d50a91105a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.373775  0.329732  0.828341]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ea4859e85940219657fd8a10031e6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.305102  0.297006  0.86927 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965c7268d9d84e999cc18a411627b5c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.281998  0.296998  0.867983]\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb7f4379b564f7d884cded4af6535a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d2cd5d751d4c748f45106ebd444c4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.295826  0.286968  0.881977]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45449868165b4bb7b693f93ae1cebce3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.255057  0.29808   0.864154]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fe4d838ea34e67a9702d7f4090f302"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.217908  0.296243  0.875967]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f71272ab9814a44bad861e555c867c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.223294  0.294551  0.882041]\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### StatsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class StatsModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(nv, n_emb)\n",
    "        self.l1 = nn.Linear(n_emb*2,10)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.l2 = nn.Linear(50,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = torch.cat([x.mean(0), x.max(0)], 0)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = nn.BatchNorm1d(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.l2(x)\n",
    "        return x.squeeze()\n",
    "        \n",
    "init_wgts(m, -1)\n",
    "m.emb.weight.data = TEXT.vocab.vectors.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = SimpleAverage().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_opt(p): return optim.Adam(p, betas=(0.,0.999))\n",
    "\n",
    "cl=4\n",
    "lrs=1e-2\n",
    "nb=len(md.trn_dl)\n",
    "t=list(split_by_idxs(list(m.children()), [1]))\n",
    "lo = LayerOptimizer(get_opt, t, lrs)\n",
    "cb=[CosAnneal(lo, nb*cl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "opt = lo.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d4563a9ce84899851449f657e07583"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228de3ed2f8f423dba306d363febfc32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.274308  0.32876   0.865473]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d052cb6cefa46a0bbe8787b7db5c049"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.244463  0.331872  0.866152]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a67ae83c0046ceb3110f5cb68345fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.194321  0.354025  0.86469 ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ded12654e74d44bb47f169332167a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.160523  0.370321  0.865353]\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 4, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postproc(arr,vocab,train): \n",
    "    return [1 if o==1 else 0 for o in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True)\n",
    "LABEL = data.Field(sequential=False, postprocessing=postproc)\n",
    "trn, test = datasets.IMDB.splits(TEXT, LABEL, root='tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_emb(x): return x.uniform_(-0.05,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vectors from .vector_cache/glove.6B.300d.pt\n"
     ]
    }
   ],
   "source": [
    "vocab_size=5000\n",
    "\n",
    "TEXT.build_vocab(trn, vectors='glove.6B.300d', max_size=vocab_size, unk_init=init_emb)\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nv=len(TEXT.vocab.itos)\n",
    "hs=70\n",
    "n_emb=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad=TEXT.vocab.stoi['<pad>']\n",
    "trn_iter, test_iter = data.BucketIterator.splits((trn, test), batch_size=64, repeat=False)\n",
    "md = ModelData('.', create_td(trn_iter), create_td(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'wmt-lstm' : 'https://s3.amazonaws.com/research.metamind.io/cove/wmtlstm-b142a7f2.pth'\n",
    "}\n",
    "\n",
    "model_cache = os.path.join('tmp/', '.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MTLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(nv, n_emb)\n",
    "        self.rnn = nn.LSTM(300, 300, num_layers=2, bidirectional=True)\n",
    "        self.rnn.load_state_dict(model_zoo.load_url(model_urls['wmt-lstm'], model_dir=model_cache))\n",
    "        self.drop = nn.Dropout(0.75)\n",
    "        self.l1 = nn.Linear(600, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x, _ = self.rnn(x, None)\n",
    "        x = self.l1(self.drop(x[-1]))\n",
    "        return x.squeeze()\n",
    "\n",
    "m = MTLSTM().cuda()\n",
    "m.emb.weight.data = TEXT.vocab.vectors.cuda()\n",
    "for p in m.rnn.parameters(): p.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_opt(p): return optim.Adam(p, betas=(0.,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl=1\n",
    "lrs=1e-2*2\n",
    "nb=len(md.trn_dl)\n",
    "t=list(split_by_idxs(list(m.children()), [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lo = LayerOptimizer(get_opt, t, lrs)\n",
    "cb=[CosAnneal(lo, nb*cl)]\n",
    "opt = lo.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477a5ac1e707422481c24912744e0675"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11761a86df114903a853e7e2864de827"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.497202  0.485905  0.760758]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in m.emb.parameters(): p.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt,lrs/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee76d91fbe9540ed8f5c40b25b93aa70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c734f17f3ca24bebbb2f75752b6d1f2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.379714  0.474497  0.776455]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in m.emb.parameters(): p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_lrs(opt,lrs/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234ddec6d358463eaaa5bc99f4e5f826"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cda075e11248edb442cda1e8190c5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.484556  0.48486   0.761189]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:9: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in m.rnn.parameters(): p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lo = LayerOptimizer(get_opt, t, lrs/10)\n",
    "cb=[CosAnneal(lo, nb*cl)]\n",
    "opt = lo.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed343ca63d74c43838de5530ec173ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4896efad08428e88f64e84ace00695"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-213985b89f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m fit(m, md, 1, F.binary_cross_entropy_with_logits, opt, \n\u001b[0;32m----> 2\u001b[0;31m     metrics=[accuracy_thresh(0.5)], callbacks=cb)\n\u001b[0m",
      "\u001b[0;32m/data/jhoward/github/deeplearning/nbs/pt_models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(m, data, epochs, crit, opt, metrics, callbacks)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/jhoward/github/deeplearning/nbs/pt_models.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(m, opt, xs, y, crit)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_train_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, F.binary_cross_entropy_with_logits, opt, \n",
    "    metrics=[accuracy_thresh(0.5)], callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Translation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re, spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'de'\u001b[0m\n",
      "\n",
      "    Only loading the 'de' tokenizer.\n",
      "\n",
      "\n",
      "\u001b[93m    Warning: no model found for 'en'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "EN = data.Field(tokenize=tokenize_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From https://wit3.fbk.eu/archive/2016-01//texts/de/en/de-en.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path='/data/jhoward/github/deeplearning/nbs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': <torchtext.data.field.Field object at 0x7f7260609048>, 'trg': <torchtext.data.field.Field object at 0x7f7260609128>}\n",
      "209772\n",
      "{'src': ['@URL@'], 'trg': ['@URL@']}\n",
      "{'src': ['BL', ':', 'Diese', 'Würmer', 'haben', 'kein', 'Verdauungssystem', '.', 'Sie', 'haben', 'keinen', 'Mund', '.'], 'trg': ['BL', ':', 'These', 'worms', 'have', 'no', 'digestive', 'system', '.', 'They', 'have', 'no', 'mouth', '.']}\n"
     ]
    }
   ],
   "source": [
    "trn, val = datasets.TranslationDataset.splits(\n",
    "    path=path+'tmp/de-en/', train='train.tags.de-en',\n",
    "    validation='IWSLT16.TED.tst2013.de-en', exts=('.de', '.en'),\n",
    "    fields=(DE, EN))\n",
    "\n",
    "print(trn.fields)\n",
    "print(len(trn))\n",
    "print(vars(trn[0]))\n",
    "print(vars(trn[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DE.build_vocab(train.src, min_freq=3)\n",
    "EN.build_vocab(train.trg, max_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 293485), ('.', 205869), ('die', 85250), ('und', 77141), ('der', 56257), ('ist', 51461), ('das', 45803), ('zu', 44547), ('in', 44314), ('ich', 39040)]\n",
      "136046\n",
      "[(',', 248240), ('.', 196796), ('the', 155955), ('to', 97498), ('of', 91549), ('and', 84765), ('a', 82235), ('that', 69796), ('I', 63840), ('in', 58086)]\n",
      "65325\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "    (train, val), batch_size=3, device=0)\n",
    "\n",
    "print(DE.vocab.freqs.most_common(10))\n",
    "print(len(DE.vocab.freqs))\n",
    "print(EN.vocab.freqs.most_common(10))\n",
    "print(len(EN.vocab.freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    22   1004    104\n",
      "    24      6     38\n",
      "    84    754     81\n",
      "   262   4097    250\n",
      "     2     95     41\n",
      "    19   1610    459\n",
      "  7448     47    202\n",
      "  1387   3758  24275\n",
      "  2424   1422  10394\n",
      "    17      7    816\n",
      "     0      2      2\n",
      "  1070     19      8\n",
      "     7    827     66\n",
      "     2   1001     11\n",
      "   737      2     94\n",
      "    11   1117    124\n",
      "    44   2107      2\n",
      "  6154      5    157\n",
      "     2     11     59\n",
      "   145    221      7\n",
      "    12     63    166\n",
      "    15  13079   4817\n",
      "  1164      2      2\n",
      "    53     20     14\n",
      "     2    259    167\n",
      "   190      2      9\n",
      "    41     19    598\n",
      "     2     15      5\n",
      "    30     17     94\n",
      "    12   6790    182\n",
      "  5708   2729    479\n",
      "   137    663      9\n",
      "  2511      3    228\n",
      " 12106      1      3\n",
      "   691      1      1\n",
      "  1164      1      1\n",
      "    53      1      1\n",
      "     3      1      1\n",
      "[torch.cuda.LongTensor of size 38x3 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "    17    300     94\n",
      "    51      6     12\n",
      "    28      4     67\n",
      "    18    186    400\n",
      "  1654   5148      4\n",
      "     9      5  14618\n",
      "  3638   1068     71\n",
      "   986     11     15\n",
      "    12      4  38390\n",
      "    11   1432     49\n",
      "   185   1077  16592\n",
      "     8     12   5873\n",
      " 10726      9      2\n",
      "   809    421     10\n",
      "     2   2404     34\n",
      "    10      2    182\n",
      "   298    421     13\n",
      "    18   2007      9\n",
      "  8434      7      2\n",
      "     9      2     74\n",
      "    16     10     71\n",
      "   101     76     15\n",
      "   529      2   4884\n",
      "    14      4      5\n",
      "    55  10104    886\n",
      "    47      2     28\n",
      "    16     27     13\n",
      "   529     39    191\n",
      "   175    262      7\n",
      "   109      9    217\n",
      "   678     25     13\n",
      " 10726    522    129\n",
      "   394      8    190\n",
      "     3   1801    385\n",
      "     1   4444      3\n",
      "     1      3      1\n",
      "[torch.cuda.LongTensor of size 36x3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.src)\n",
    "print(batch.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
