{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from torch_imports import *\n",
    "from torchtext import vocab, data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pt_models import *\n",
    "from dataset_pt import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postproc(arr,vocab,train): \n",
    "    return [1 if o==1 else 0 for o in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach 1:\n",
    "# set up fields\n",
    "TEXT = data.Field(lower=True, fix_length=500)\n",
    "LABEL = data.Field(sequential=False, postprocessing=postproc)\n",
    "\n",
    "# make splits for data\n",
    "trn, test = datasets.IMDB.splits(TEXT, LABEL, root='tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn.fields {'text': <torchtext.data.field.Field object at 0x7f34cd1571d0>, 'label': <torchtext.data.field.Field object at 0x7f34cd157160>}\n",
      "len(trn) 25000\n",
      "vars(trn[0]) {'text': ['i', 'remember', 'when', 'i', 'first', 'saw', 'this', 'short,', 'i', 'was', 'really', 'laughing', 'so', 'hard,', 'that', 'like', 'with', 'a', 'lot', 'of', 'other', 'films', 'that', 'i', 'have', 'seen,', 'no', 'sound', 'came', 'out!', 'curly', 'is', 'really', 'great', 'at', '\"singing\"', 'opera', 'in', 'this', 'one,', 'i', 'am', 'surprised', 'that', 'he', 'did', 'not', 'consider', 'a', 'career', 'as', 'a', 'professional', 'singer,', 'because', 'he', 'was', 'really', 'good!', '<br', '/><br', '/>if', 'you', 'noticed,', 'this', 'was', 'filmed', 'near', 'the', 'end', 'of', \"curly's\", 'career', 'as', 'a', 'stooge,', 'you', 'could', 'really', 'tell', 'he', 'had', 'changed,', 'because', 'he', 'had', 'lost', 'weight', 'and', 'was', 'thinner,', 'his', 'voice', 'was', 'deepening,', 'his', 'face', 'was', 'getting', 'lined', 'with', 'wrinkles,', 'though', 'he', 'still', 'could', 'pull', 'it', 'off,', 'he', 'looked', 'like', 'he', 'was', 'fifty', 'at', 'the', 'age', 'of', 'forty.', 'this', 'was', 'because', 'he', 'was', 'suffering', 'many', 'minor', 'strokes', 'before', 'his', 'big', 'one', 'that', 'ended', 'his', 'career.', 'be', 'he', 'still', 'managed', 'to', 'pull', 'it', 'off', 'in', 'his', 'last', 'ones!', '<br', '/><br', '/>if', 'you', \"don't\", 'mind', 'the', 'fact', 'that', 'curly', 'was', 'really', 'getting', 'very', 'ill', 'at', 'this', 'point,', 'this', 'is', 'actually', 'one', 'of', 'their', 'funniest', 'shorts.', 'i', 'know', 'that', 'i', \"didn't\", 'mind', 'the', 'fact', 'that', 'curly', 'was', 'really', 'changing,', 'because', 'i', 'still', 'thought', 'that', 'he', 'was', 'great!', '<br', '/><br', '/>10/10'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "# print information about the data\n",
    "print('trn.fields', trn.fields)\n",
    "print('len(trn)', len(trn))\n",
    "print('vars(trn[0])', vars(trn[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vectors from .vector_cache/glove.6B.100d.pt\n",
      "len(TEXT.vocab) 5002\n",
      "TEXT.vocab.vectors.size() torch.Size([5002, 100])\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "TEXT.build_vocab(trn, vectors='glove.6B.100d', max_size=vocab_size)\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "# print vocab information\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('TEXT.vocab.vectors.size()', TEXT.vocab.vectors.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'neg', 'pos']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "-0.0382 -0.2449  0.7281  ...  -0.1459  0.8278  0.2706\n",
       "          ...             ⋱             ...          \n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "-0.0626  0.9136  0.4275  ...  -0.6858  0.5875  0.3384\n",
       " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "[torch.FloatTensor of size 5002x100]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make iterator for splits\n",
    "trn_iter, test_iter = data.BucketIterator.splits((trn, test), batch_size=64, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print batch information\n",
    "batch = next(iter(trn_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    2     9    21  ...     12     2    48\n",
      " 3106   236  2808  ...      7   998   668\n",
      "    7    12   659  ...      3   679   553\n",
      "       ...          ⋱          ...       \n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "    1     1     1  ...      1     1     1\n",
      "[torch.cuda.LongTensor of size 500x64 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(batch.text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       " 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n",
       "-0.0382 -0.2449  0.7281 -0.3996  0.0832  0.0440 -0.3914  0.3344 -0.5755  0.0875\n",
       "-0.2709  0.0440 -0.0203 -0.1740  0.6444  0.7121  0.3551  0.4714 -0.2964  0.5443\n",
       "-0.0720  0.2313  0.0237 -0.5064  0.3392  0.1959 -0.3294  0.1836 -0.1806  0.2896\n",
       "-0.1529 -0.2428  0.8984  0.1700  0.5352  0.4878 -0.5883 -0.1798 -1.3581  0.4254\n",
       "-0.1897  0.0500  0.1908 -0.0492 -0.0897  0.2101 -0.5495  0.0984 -0.2014  0.3424\n",
       "-0.5426  0.4148  1.0322 -0.4024  0.4669  0.2182 -0.0749  0.4733  0.0810 -0.2208\n",
       " 0.0857 -0.2220  0.1657  0.1337  0.3824  0.3540  0.0129  0.2246 -0.4382  0.5016\n",
       "-0.0465  0.6197  0.5665 -0.4658 -1.1890  0.4460  0.0660  0.3191  0.1468 -0.2212\n",
       "[torch.FloatTensor of size 10x10]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251637"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab.Vocab.__init__.<locals>.<lambda>>,\n",
       "            {'neg': 1, 'pos': 2})"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad=TEXT.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextDataLoader():\n",
    "    def __init__(self, src, x_fld, y_fld):\n",
    "        self.src,self.x_fld,self.y_fld = src,x_fld,y_fld\n",
    "        \n",
    "    def __len__(self): return len(self.src)\n",
    "    \n",
    "    def __iter__(self): \n",
    "        self.src_iter = iter(self.src)\n",
    "        return self\n",
    "        \n",
    "    def __next__(self): \n",
    "        try:\n",
    "            b = next(self.src_iter)\n",
    "            return getattr(b, self.x_fld), getattr(b, self.y_fld)\n",
    "        except StopIteration: \n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_td(it): return TextDataLoader(it, 'text', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ModelData('.', create_td(trn_iter), create_td(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x,y=next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf=100\n",
    "n_emb=32\n",
    "nv=len(TEXT.vocab.itos)\n",
    "\n",
    "class SimpleLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(nv, n_emb, padding_idx=pad)#, max_norm=1., norm_type=2)\n",
    "        self.emb.weight.data.uniform_(-0.05,0.05)\n",
    "        self.l1 = nn.Linear(500*n_emb, nf)\n",
    "        self.l2 = nn.Linear(nf, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ns,bs = x.size()\n",
    "        x = self.emb(x)\n",
    "        x = x.transpose(0,1).contiguous().view(bs,-1)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.dropout(x, 0.7)\n",
    "        return self.l2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SimpleLinear().cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3486e163d143709b182808dfdaa648"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4547e219184451f946b3d7c4e39fc92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.382181  0.338946  0.854867]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54558d38c01e4a0688c168a172e9fc1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.260172  0.32782   0.860294]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, F.cross_entropy, opt, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True)\n",
    "LABEL = data.Field(sequential=False, postprocessing=postproc)\n",
    "trn, test = datasets.IMDB.splits(TEXT, LABEL, root='tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vectors from .vector_cache/glove.6B.100d.pt\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(trn, vectors='glove.6B.100d', max_size=vocab_size)\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_iter, test_iter = data.BucketIterator.splits((trn, test), batch_size=64, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ModelData('.', create_td(trn_iter), create_td(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs=100\n",
    "n_emb=32\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(len(TEXT.vocab.itos), n_emb, padding_idx=pad)\n",
    "        self.emb.weight.data.uniform_(-0.05,0.05)\n",
    "        self.rnn = nn.LSTM(n_emb, hs, num_layers=1, dropout=0.2)\n",
    "        self.out = nn.Linear(hs, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size(1)\n",
    "        x = self.emb(x)\n",
    "        c0 = Variable(torch.zeros(1,bs,hs)).cuda()\n",
    "        h0 = Variable(torch.zeros(1,bs,hs)).cuda()\n",
    "        outp,_ = self.rnn(x, (h0,c0))\n",
    "        return self.out(outp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = SimpleLSTM().cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb90cedd44f4bcbaf862b280f4bf4ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a900798a6bf4d9ea30d4a9ccfb12f5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhoward/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.260364  0.299499  0.873649]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed3b098ebdd4c15b48d46698686bda5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.220552  0.325146  0.868175]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 2, F.cross_entropy, opt, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Translation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re, spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'de'\u001b[0m\n",
      "\n",
      "    Only loading the 'de' tokenizer.\n",
      "\n",
      "\n",
      "\u001b[93m    Warning: no model found for 'en'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = re.compile('(<url>.*</url>)')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(url.sub('@URL@', text))]\n",
    "\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "EN = data.Field(tokenize=tokenize_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From https://wit3.fbk.eu/archive/2016-01//texts/de/en/de-en.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path='/data/jhoward/github/deeplearning/nbs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': <torchtext.data.field.Field object at 0x7f7260609048>, 'trg': <torchtext.data.field.Field object at 0x7f7260609128>}\n",
      "209772\n",
      "{'src': ['@URL@'], 'trg': ['@URL@']}\n",
      "{'src': ['BL', ':', 'Diese', 'Würmer', 'haben', 'kein', 'Verdauungssystem', '.', 'Sie', 'haben', 'keinen', 'Mund', '.'], 'trg': ['BL', ':', 'These', 'worms', 'have', 'no', 'digestive', 'system', '.', 'They', 'have', 'no', 'mouth', '.']}\n"
     ]
    }
   ],
   "source": [
    "train, val = datasets.TranslationDataset.splits(\n",
    "    path=path+'tmp/de-en/', train='train.tags.de-en',\n",
    "    validation='IWSLT16.TED.tst2013.de-en', exts=('.de', '.en'),\n",
    "    fields=(DE, EN))\n",
    "\n",
    "print(train.fields)\n",
    "print(len(train))\n",
    "print(vars(train[0]))\n",
    "print(vars(train[100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DE.build_vocab(train.src, min_freq=3)\n",
    "EN.build_vocab(train.trg, max_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 293485), ('.', 205869), ('die', 85250), ('und', 77141), ('der', 56257), ('ist', 51461), ('das', 45803), ('zu', 44547), ('in', 44314), ('ich', 39040)]\n",
      "136046\n",
      "[(',', 248240), ('.', 196796), ('the', 155955), ('to', 97498), ('of', 91549), ('and', 84765), ('a', 82235), ('that', 69796), ('I', 63840), ('in', 58086)]\n",
      "65325\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "    (train, val), batch_size=3, device=0)\n",
    "\n",
    "print(DE.vocab.freqs.most_common(10))\n",
    "print(len(DE.vocab.freqs))\n",
    "print(EN.vocab.freqs.most_common(10))\n",
    "print(len(EN.vocab.freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "    22   1004    104\n",
      "    24      6     38\n",
      "    84    754     81\n",
      "   262   4097    250\n",
      "     2     95     41\n",
      "    19   1610    459\n",
      "  7448     47    202\n",
      "  1387   3758  24275\n",
      "  2424   1422  10394\n",
      "    17      7    816\n",
      "     0      2      2\n",
      "  1070     19      8\n",
      "     7    827     66\n",
      "     2   1001     11\n",
      "   737      2     94\n",
      "    11   1117    124\n",
      "    44   2107      2\n",
      "  6154      5    157\n",
      "     2     11     59\n",
      "   145    221      7\n",
      "    12     63    166\n",
      "    15  13079   4817\n",
      "  1164      2      2\n",
      "    53     20     14\n",
      "     2    259    167\n",
      "   190      2      9\n",
      "    41     19    598\n",
      "     2     15      5\n",
      "    30     17     94\n",
      "    12   6790    182\n",
      "  5708   2729    479\n",
      "   137    663      9\n",
      "  2511      3    228\n",
      " 12106      1      3\n",
      "   691      1      1\n",
      "  1164      1      1\n",
      "    53      1      1\n",
      "     3      1      1\n",
      "[torch.cuda.LongTensor of size 38x3 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      "    17    300     94\n",
      "    51      6     12\n",
      "    28      4     67\n",
      "    18    186    400\n",
      "  1654   5148      4\n",
      "     9      5  14618\n",
      "  3638   1068     71\n",
      "   986     11     15\n",
      "    12      4  38390\n",
      "    11   1432     49\n",
      "   185   1077  16592\n",
      "     8     12   5873\n",
      " 10726      9      2\n",
      "   809    421     10\n",
      "     2   2404     34\n",
      "    10      2    182\n",
      "   298    421     13\n",
      "    18   2007      9\n",
      "  8434      7      2\n",
      "     9      2     74\n",
      "    16     10     71\n",
      "   101     76     15\n",
      "   529      2   4884\n",
      "    14      4      5\n",
      "    55  10104    886\n",
      "    47      2     28\n",
      "    16     27     13\n",
      "   529     39    191\n",
      "   175    262      7\n",
      "   109      9    217\n",
      "   678     25     13\n",
      " 10726    522    129\n",
      "   394      8    190\n",
      "     3   1801    385\n",
      "     1   4444      3\n",
      "     1      3      1\n",
      "[torch.cuda.LongTensor of size 36x3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.src)\n",
    "print(batch.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
